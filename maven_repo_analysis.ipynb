{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4a567ae28e945679",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.use(\"pgf\")\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": True,\n",
    "    \"pgf.rcfonts\": False,\n",
    "    \"pgf.texsystem\": \"pdflatex\",\n",
    "})\n",
    "from urllib.parse import urlparse\n",
    "from scipy.stats import pearsonr\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85257ab0414d3228",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b2eeee81b5706fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jacob\\AppData\\Local\\Temp\\ipykernel_14416\\2805030735.py:1: DtypeWarning: Columns (12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  all_poms_before_sampling = pd.read_csv(\"data/all_poms_before_sampling.csv\")\n",
      "C:\\Users\\jacob\\AppData\\Local\\Temp\\ipykernel_14416\\2805030735.py:2: DtypeWarning: Columns (5,6,7,8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  all_repos_before_sampling = pd.read_csv(\"data/all_repos_before_sampling.csv\")\n"
     ]
    }
   ],
   "source": [
    "all_poms_before_sampling = pd.read_csv(\"data/all_poms_before_sampling.csv\")\n",
    "all_repos_before_sampling = pd.read_csv(\"data/all_repos_before_sampling.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b2dbb632f66e23",
   "metadata": {},
   "source": [
    "## Random Sampling and removing duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1e099eb87c25d466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_poms: 934266 -> 199188\n"
     ]
    }
   ],
   "source": [
    "all_poms = all_poms_before_sampling.copy()\n",
    "l_all_poms = len(all_poms)\n",
    "\n",
    "random_seed = 42\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "# Shuffle the DataFrame randomly\n",
    "all_poms = all_poms.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Remove duplicates from poms to only mantain one version of each package\n",
    "all_poms = all_poms.drop_duplicates(subset=['groupId', 'artifactId'])\n",
    "\n",
    "# Reset the index of the deduplicated DataFrame\n",
    "all_poms.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(\"all_poms: \" + str(l_all_poms) + \" -> \" + str(len(all_poms)))\n",
    "\n",
    "# only take rows that are later than or in 2016 \n",
    "all_poms['releaseDate'] = pd.to_datetime(all_poms['releaseDate'])\n",
    "all_poms = all_poms[all_poms['releaseDate'].dt.year >= 2016]\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "all_poms.to_csv('data/all_poms.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "969424e68378a2ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_repos: 157387 -> 16781\n"
     ]
    }
   ],
   "source": [
    "all_repos = all_repos_before_sampling.copy()\n",
    "l_all_repos = len(all_repos)\n",
    "\n",
    "# Drop duplicates from repos\n",
    "all_repos = all_repos.drop_duplicates(subset=['id', 'pomId', 'name', 'url'])\n",
    "all_repos = all_repos[all_repos['pomId'].isin(all_poms['id'])]\n",
    "\n",
    "print(\"all_repos: \" + str(l_all_repos) + \" -> \" + str(len(all_repos)))\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "all_repos.to_csv('data/all_repos.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8bad9c57b0aed4cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_poms_repos: 16781\n"
     ]
    }
   ],
   "source": [
    "# <erge poms and repos and name the id of left id_pom and id_repo\n",
    "all_poms_repos = pd.merge(all_poms, all_repos, left_on='id', right_on='pomId', how='inner')\n",
    "all_poms_repos = all_poms_repos.rename(columns={'id_x': 'id_pom', 'id_y': 'id_repo'})\n",
    "all_poms_repos = all_poms_repos.rename(columns={'url_x': 'url_pom', 'url_y': 'url_repo'})\n",
    "\n",
    "print(\"all_poms_repos: \" + str(len(all_poms_repos)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6f1d44b5d7d5e5",
   "metadata": {},
   "source": [
    "# Showing the distribution of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "41fd4e91cbe3fcbf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T10:35:40.197931200Z",
     "start_time": "2024-01-22T10:35:40.193419700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   releaseDate  count\n",
      "0         2016  23701\n",
      "1         2017  21406\n",
      "2         2018  24571\n",
      "3         2019  31089\n",
      "4         2020  19561\n",
      "5         2021  21559\n",
      "6         2022  23481\n",
      "7         2023  33815\n"
     ]
    }
   ],
   "source": [
    "df = all_poms.copy()\n",
    "df['releaseDate'] = pd.to_datetime(df['releaseDate'])\n",
    "\n",
    "# Group by year and count the rows\n",
    "yearly_counts_v2 = df.groupby(df['releaseDate'].dt.year).size().reset_index(name='count')\n",
    "\n",
    "# Display the result\n",
    "print(yearly_counts_v2)\n",
    "\n",
    "plt.figure(figsize=(3.5, 3))\n",
    "ax = sns.barplot(x=\"releaseDate\", y=\"count\", data=yearly_counts_v2, palette='viridis')\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=45, horizontalalignment='right', fontsize=8)\n",
    "plt.xticks(fontsize=8)\n",
    "plt.yticks(fontsize=8)\n",
    "ax.yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos: '{:,.0f}'.format(x/1000)))\n",
    "plt.xlabel('Year', fontsize=8)\n",
    "plt.ylabel('Number of Packages (x1000)', fontsize=8)\n",
    "plt.savefig('graphs/packages_per_year.pgf')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed1526765775d18",
   "metadata": {},
   "source": [
    "# Average packages with at least 1 repository per year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "3b6df3e643e4eacf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearsons correlation: -0.791 p-value:  0.01948714873964627\n"
     ]
    }
   ],
   "source": [
    "df = all_poms.copy()\n",
    "df['releaseDate'] = pd.to_datetime(all_poms['releaseDate'])\n",
    "\n",
    "def calc_at_least_one_repo_percentage_over_time(repos, period='Y'):\n",
    "    # Filter the DataFrame\n",
    "    poms_with_repos = repos[repos['repositoriesAmount'] >= 1]\n",
    "\n",
    "    # Resample the data by the desired time period and calculate the percentages\n",
    "    percentages = poms_with_repos.resample(period, on='releaseDate')['id'].nunique() / repos.resample(period, on='releaseDate')['id'].nunique() * 100\n",
    "\n",
    "    return percentages\n",
    "\n",
    "# Calculate the percentages over time \n",
    "percentages = calc_at_least_one_repo_percentage_over_time(df)\n",
    "\n",
    "# Convert the index to a numerical format (e.g., number of days since the start of the period)\n",
    "x = np.array(range(len(percentages.index)))\n",
    "\n",
    "# Convert the percentages to a numpy array\n",
    "y = percentages.values\n",
    "\n",
    "# Create a mask where both x and y are not nan\n",
    "mask = ~np.isnan(y)\n",
    "x = x[mask]\n",
    "y = y[mask]\n",
    "percentages = percentages[mask]\n",
    "\n",
    "plt.figure(figsize=(3.5, 3))\n",
    "plt.plot(percentages.index.year, percentages, label='Combined', color='#492c68', marker='o')\n",
    "plt.xticks(percentages.index.year, fontsize=8)\n",
    "plt.xticks(rotation=45, horizontalalignment='right')\n",
    "plt.xticks(fontsize=8)\n",
    "plt.yticks(fontsize=8)\n",
    "plt.xlabel('Year', fontsize=8)\n",
    "plt.ylabel('Percentage of packages with at least 1 repository (%)', fontsize=8)\n",
    "plt.savefig('graphs/packages_with_repositories_percentages.pgf')\n",
    "plt.close()\n",
    "\n",
    "# Find pearson correlation between percentage and time\n",
    "corr, p_val = pearsonr(x, y)\n",
    "print('Pearsons correlation: %.3f' % corr, \"p-value: \", p_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f85ea3fa28eb851e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Focusing on the range of 'repositoriesAmount' from 1 to 10\n",
    "data_repos = all_poms[(all_poms['repositoriesAmount'] >= 1) & (all_poms['repositoriesAmount'] <=10)].copy()\n",
    "\n",
    "# Calculating the percentage of packages for each repository amount\n",
    "repos_counts = data_repos['repositoriesAmount'].value_counts()\n",
    "total_packages = len(all_poms)\n",
    "percentage_repos = (repos_counts / total_packages) * 100\n",
    "\n",
    "# Sorting the index for plotting\n",
    "percentage_repos = percentage_repos.sort_index()\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(3.5, 3))\n",
    "plt.subplots_adjust(bottom=0.2)\n",
    "bars = sns.barplot(x=percentage_repos.index, y=percentage_repos.values, palette='viridis')\n",
    "plt.ylim(0, 1.2 * max(percentage_repos.values))\n",
    "plt.xticks(fontsize=8)\n",
    "plt.yticks(fontsize=8)\n",
    "\n",
    "for bar in bars.patches:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, yval + 0.05, f'{yval:.2f}%', ha='center', va='bottom', fontsize=6)\n",
    "\n",
    "plt.xlabel('Number of Repositories Specified', fontsize=8)\n",
    "plt.ylabel('Percentage of Packages', fontsize=8)\n",
    "plt.xticks(range(10))  \n",
    "ax = plt.gca() \n",
    "ax.xaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos: int(x + 1)))\n",
    "plt.savefig('graphs/repositories_count.pgf')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c3f3e3aea8d89515",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-22T10:40:33.208517100Z",
     "start_time": "2024-01-22T10:40:33.168030300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of unique IDs with at least 1 repository: 4.079163382417174%\n"
     ]
    }
   ],
   "source": [
    "def calc_at_least_one_repo_percentage(repos):\n",
    "    # Filter the DataFrame\n",
    "    poms_with_repos = repos[repos['repositoriesAmount'] >= 1]\n",
    "    \n",
    "    # Count the number of unique IDs with at least 1 repository\n",
    "    unique_ids_with_repos = poms_with_repos['id'].nunique()\n",
    "    \n",
    "    # Count the total number of unique IDs\n",
    "    total_unique_ids = repos['id'].nunique()\n",
    "    \n",
    "    # Calculate the percentage\n",
    "    percentage = (unique_ids_with_repos / total_unique_ids) * 100\n",
    "    \n",
    "    print(f'Percentage of unique IDs with at least 1 repository: {percentage}%')\n",
    "    \n",
    "\n",
    "calc_at_least_one_repo_percentage(all_poms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24294377aa9f3a7b",
   "metadata": {},
   "source": [
    "# Do repository ids commonly change when new versions of the same package are released?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9e748f99b99e8d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of groups with ID changes across versions: 0.6806385270786407%\n"
     ]
    }
   ],
   "source": [
    "def analyze_id_variations(repos):\n",
    "    # Group by groupId and artifactId\n",
    "    grouped = repos.groupby(['groupId', 'artifactId', 'url_y'])\n",
    "    changes_count = 0\n",
    "    total_groups = 0\n",
    "\n",
    "    for _, group in grouped:\n",
    "        total_groups += 1\n",
    "        # Check if there are variations in ID across different versions\n",
    "        if group['id_y'].nunique() > 1:\n",
    "            changes_count += 1\n",
    "\n",
    "    # Calculate the percentage of groups where IDs change\n",
    "    if total_groups > 0:\n",
    "        change_percentage = (changes_count / total_groups) * 100\n",
    "    else:\n",
    "        change_percentage = 0\n",
    "\n",
    "    return change_percentage\n",
    "\n",
    "merged_df = pd.merge(all_poms_before_sampling, all_repos_before_sampling, left_on='id', right_on='pomId', how='inner')\n",
    "\n",
    "# Call the function and print the result\n",
    "percentage_changes = analyze_id_variations(merged_df)\n",
    "print(f\"Percentage of groups with ID changes across versions: {percentage_changes}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d34580cde9110626",
   "metadata": {},
   "outputs": [],
   "source": [
    "maven_errors = [\n",
    "    {\"issue\": \"Forbidden\", \"error_message\": \"Forbidden (403)\"},\n",
    "    {\"issue\": \"Blocked Mirror\", \"error_message\": \"Blocked mirror\"},\n",
    "    {\"issue\": \"Not found in Central\", \"error_message\": \"Could not find\"},\n",
    "    {\"issue\": \"Non-resolvable parent POM\", \"error_message\": \"Non-resolvable parent POM\"},\n",
    "    {\"issue\": \"Does not exist\", \"error_message\": \"does not exist\"},\n",
    "    {\"issue\": \"Unknown packaging\", \"error_message\": \" Unknown packaging\"},\n",
    "    {\"issue\": \"Connection refused\", \"error_message\": \"Connection refused\"} \n",
    "]\n",
    "\n",
    "\n",
    "def match_error_messages(dataset_msgs, predefined_errors):\n",
    "    # Initialize a dictionary to count occurrences of each issue\n",
    "    issue_counts = {error['issue']: 0 for error in predefined_errors}\n",
    "\n",
    "    for dataset_msg in dataset_msgs:\n",
    "        for error in predefined_errors:\n",
    "            if error['error_message'].lower() in dataset_msg.lower():\n",
    "                issue_counts[error['issue']] += 1\n",
    "\n",
    "    return issue_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1cdf0d619229d96d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1741\n"
     ]
    }
   ],
   "source": [
    "error_all_poms = all_poms.copy()\n",
    "error_all_poms['year'] = pd.to_datetime(error_all_poms['releaseDate']).dt.year\n",
    "error_all_poms.dropna(subset=['mavenErrorMessage'], inplace=True)\n",
    "\n",
    "print(len(error_all_poms))\n",
    "grouped =  error_all_poms.groupby('year')\n",
    "\n",
    "\n",
    "# calculate percentage of error types for each year\n",
    "issues_per_year = {}\n",
    "\n",
    "for year, group in grouped:\n",
    "    error_messages = group['mavenErrorMessage'].dropna()\n",
    "    issue_counts = match_error_messages(error_messages, maven_errors)\n",
    "    total_errors = sum(issue_counts.values())\n",
    "    \n",
    "    for issue in issue_counts:\n",
    "        issue_counts[issue] = issue_counts[issue] / total_errors * 100 if total_errors > 0 else 0\n",
    "    issues_per_year[year] = issue_counts\n",
    "    \n",
    "plot_issues = ['Connection refused']\n",
    "\n",
    "# plot the results\n",
    "plt.figure(figsize=(3.5, 3))\n",
    "\n",
    "for issue in plot_issues:\n",
    "    years = list(issues_per_year.keys())\n",
    "    percentages = [issues_per_year[year][issue] for year in years]\n",
    "    plt.plot(years, percentages, marker='o', color='#492c68', label=issue)   \n",
    "    \n",
    "plt.xticks(years, fontsize=8)\n",
    "plt.xticks(rotation=45, horizontalalignment='right')\n",
    "plt.xticks(fontsize=8)\n",
    "plt.yticks(fontsize=8)\n",
    "plt.xlabel('Year', fontsize=8)\n",
    "plt.ylabel('Percentage of Connection Refused Error', fontsize=8)\n",
    "plt.savefig('graphs/connection_refused.pgf')\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "3534e14e6e8fc82c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of packages that have an error: 0.8740705783124062%\n",
      "Percentage of packages with repositories that have an error: 0.8861538461538463%\n",
      "Percentage of packages without repositories that have an error: 0.8735704378320379%\n",
      "T-statistic: -0.1193421947180227\n",
      "P-value: 0.9050043761588642\n"
     ]
    }
   ],
   "source": [
    "# Calculate the percentage of packages that have an error\n",
    "total_packages = len(all_poms)\n",
    "poms_with_errors = all_poms.dropna(subset=['mavenErrorMessage'], inplace=False)\n",
    "packages_with_errors = len(poms_with_errors)\n",
    "percentage_with_errors = (packages_with_errors / total_packages) * 100\n",
    "\n",
    "print(f\"Percentage of packages that have an error: {percentage_with_errors}%\")\n",
    "\n",
    "# Filter the DataFrame to include only rows where repositoriesAmount is greater than or equal to 1\n",
    "packages_with_repos = all_poms[all_poms['repositoriesAmount'] >= 1].copy()\n",
    "\n",
    "# Count the number of packages that have one or more repositories\n",
    "num_packages_with_repos = len(packages_with_repos)\n",
    "\n",
    "# Filter the DataFrame to include only rows where mavenErrorMessage is not null\n",
    "packages_with_repos_and_errors = packages_with_repos.dropna(subset=['mavenErrorMessage'])\n",
    "\n",
    "# Count the number of packages that have one or more repositories and have an error\n",
    "num_packages_with_repos_and_errors = len(packages_with_repos_and_errors)\n",
    "\n",
    "percentage_packages_with_repos_with_error =  num_packages_with_repos_and_errors / num_packages_with_repos * 100\n",
    "\n",
    "print(f\"Percentage of packages with repositories that have an error: {percentage_packages_with_repos_with_error}%\")\n",
    "\n",
    "# Filter the DataFrame to include only rows where repositoriesAmount is 0\n",
    "packages_with_no_repos = all_poms[all_poms['repositoriesAmount'] == 0].copy()\n",
    "\n",
    "# Filter the DataFrame to include only rows where repositoriesAmount is greater than or equal to 1\n",
    "packages_with_repos = all_poms[all_poms['repositoriesAmount'] >= 1].copy()\n",
    "\n",
    "# Calculate the percentage of errors for packages with no repositories\n",
    "packages_with_no_repos['has_error'] = packages_with_no_repos['mavenErrorMessage'].notna()\n",
    "percentage_errors_no_repos = packages_with_no_repos['has_error'].mean()\n",
    "print(f\"Percentage of packages without repositories that have an error: {percentage_errors_no_repos*100}%\")\n",
    "\n",
    "# Calculate the percentage of errors for packages with repositories\n",
    "packages_with_repos['has_error'] = packages_with_repos['mavenErrorMessage'].notna()\n",
    "percentage_errors_with_repos = packages_with_repos['has_error'].mean()\n",
    "\n",
    "# Perform the t-test\n",
    "t_stat, p_val = stats.ttest_ind(packages_with_no_repos['has_error'], packages_with_repos['has_error'])\n",
    "\n",
    "print(f\"T-statistic: {t_stat}\")\n",
    "print(f\"P-value: {p_val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4182231e0845d72b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of packages with repository URL in error message: 0.15493713127942316%\n"
     ]
    }
   ],
   "source": [
    "# Check for every row in in all_poms_repos whether the url_repo is in the error message\n",
    "def check_url_in_error(row):\n",
    "    if pd.isnull(row['mavenErrorMessage']):\n",
    "        return np.nan\n",
    "    elif row['url_repo'] in row['mavenErrorMessage']:\n",
    "        return row['mavenErrorMessage']\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "url_poms_repos = all_poms_repos.copy()\n",
    "urls_with_errors = url_poms_repos.dropna(subset=['mavenErrorMessage', 'url_repo'], inplace=False).copy()\n",
    "urls_with_errors['error_message_with_url'] = urls_with_errors.apply(check_url_in_error, axis=1)\n",
    "\n",
    "# Percentage of errors containing repo url \n",
    "packages_with_url_as_error = urls_with_errors.dropna(subset=['error_message_with_url'], inplace=False)\n",
    "deduplicated_packages = packages_with_url_as_error.drop_duplicates(subset=['groupId', 'artifactId', 'version'])\n",
    "\n",
    "percentage_packages_with_url_as_error = len(deduplicated_packages) / len(all_poms_repos) * 100\n",
    "print(f\"Percentage of packages with repository URL in error message: {percentage_packages_with_url_as_error}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42ffa00eac697b1",
   "metadata": {},
   "source": [
    "# Testing availability of repository URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "1ce936bc934950dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Initialize a cache dictionary to store URL status codes\n",
    "url_cache = {}\n",
    "\n",
    "# Function to check URL availability and use cache\n",
    "def check_url_availability(url):\n",
    "    if url in url_cache:\n",
    "        return url_cache[url]\n",
    "    try:\n",
    "        response = requests.get(url, timeout=2)\n",
    "        status_code = response.status_code\n",
    "        url_cache[url] = status_code  # Cache the result\n",
    "        return status_code\n",
    "    except requests.exceptions.RequestException:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ba881fb8a53c5820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Percentage of 200 Status Codes: 0.0%\n",
      "Total Percentage of Other Status Codes: 100.0%\n"
     ]
    }
   ],
   "source": [
    "# Strip right of / and get unique urls\n",
    "all_poms_repos_copy = all_poms_repos.copy()\n",
    "all_poms_repos_copy['url_repo'] = all_poms_repos_copy['url_repo'].str.rstrip('/')\n",
    "unique_urls_repos = all_poms_repos_copy.drop_duplicates(subset=['url_repo'], keep='first').copy()\n",
    "\n",
    "# Apply the function to each row and create a new 'stillAvailable' column\n",
    "unique_urls_repos['stillAvailable'] = unique_urls_repos['url_repo'].apply(check_url_availability)\n",
    "\n",
    "# Classify NaN values as timeouts\n",
    "unique_urls_repos['stillAvailable'] = unique_urls_repos['stillAvailable'].fillna('Timeout')\n",
    "\n",
    "# Calculate the percentage of 200 status codes\n",
    "total_percentage_200 = (unique_urls_repos['stillAvailable'] == 200).mean() * 100\n",
    "\n",
    "# Calculate the percentage of other status codes\n",
    "total_percentage_other = 100 - total_percentage_200\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(3, 2.5))\n",
    "plt.pie([total_percentage_200, total_percentage_other], labels=['Reachable', 'Unreachable'], autopct='%1.1f%%', startangle=90, colors=['#74758d', '#738292'], textprops={'fontsize': 10})\n",
    "plt.subplots_adjust(left=0.2, right=0.8)\n",
    "plt.savefig('graphs/unreachable_urls.pgf')\n",
    "plt.close()\n",
    "\n",
    "# Step 5: Print the percentages\n",
    "print(f'Total Percentage of 200 Status Codes: {total_percentage_200:.1f}%')\n",
    "print(f'Total Percentage of Other Status Codes: {total_percentage_other:.1f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "cdbe9158b4523cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the dataframes on 'url_repo'\n",
    "all_poms_repos_copy = all_poms_repos.copy()\n",
    "merged_df = pd.merge(all_poms_repos_copy, unique_urls_repos[['url_repo', 'stillAvailable']], on='url_repo', how='left')\n",
    "\n",
    "# Convert the 'releaseDate' column to datetime\n",
    "merged_df['releaseDate'] = pd.to_datetime(merged_df['releaseDate'])\n",
    "\n",
    "# Extract the year from 'releaseDate'\n",
    "merged_df['year'] = merged_df['releaseDate'].dt.year\n",
    "\n",
    "# Group by year\n",
    "grouped = merged_df.groupby('year')\n",
    "\n",
    "# Initialize a dictionary to store the percentage of unreachable URLs per year\n",
    "unreachable_percentage_per_year = {}\n",
    "\n",
    "# Calculate the percentage of unreachable URLs per year\n",
    "for year, group in grouped:\n",
    "    total_urls = len(group)\n",
    "    unreachable_urls = len(group[group['stillAvailable'] != 200])\n",
    "    unreachable_percentage = (unreachable_urls / total_urls) * 100 if total_urls > 0 else 0\n",
    "    unreachable_percentage_per_year[year] = unreachable_percentage\n",
    "\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(3.5, 3))\n",
    "plt.xticks(fontsize=8)\n",
    "plt.yticks(fontsize=8)\n",
    "plt.xticks(list(unreachable_percentage_per_year.keys()), fontsize=8)\n",
    "plt.xticks(rotation=45, horizontalalignment='right')\n",
    "plt.plot(list(unreachable_percentage_per_year.keys()), list(unreachable_percentage_per_year.values()), marker='o', color='#492c68',)\n",
    "plt.xlabel('Year', fontsize=8)\n",
    "plt.ylabel('Percentage of Unreachable URLs (%)', fontsize=8)\n",
    "plt.savefig('graphs/unreachable_urls_per_year.pgf')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8aeaf8156001da",
   "metadata": {},
   "source": [
    "## Http vs Https"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "27346b66d5fd779f",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_poms_repos_df = all_poms_repos\n",
    "updated_poms_repos_df['releaseYear'] = pd.to_datetime(updated_poms_repos_df['releaseDate']).dt.year\n",
    "\n",
    "# Filtering data for the years 2015 to 2023\n",
    "filtered_years_df = updated_poms_repos_df[(updated_poms_repos_df['releaseYear'] >= 2016) & (updated_poms_repos_df['releaseYear'] <= 2023)]\n",
    "\n",
    "# Categorizing the URL type with the adjusted criteria, handling NaN or non-string values\n",
    "filtered_years_df['url_type'] = filtered_years_df['url_repo'].apply(\n",
    "    lambda x: 'https' if isinstance(x, str) and 'https://' in x else ('http' if isinstance(x, str) and 'http://' in x else 'other')\n",
    ")\n",
    "\n",
    "# Counting the usage of HTTP, HTTPS, and other URLs per year\n",
    "http_https_other_counts = filtered_years_df.groupby(['releaseYear', 'url_type']).size().unstack(fill_value=0)\n",
    "\n",
    "# Converting counts to percentages of the total for each year\n",
    "http_https_other_percentages = http_https_other_counts.div(http_https_other_counts.sum(axis=1), axis=0) * 100\n",
    "\n",
    "# Remove other from plot (these were urls that that did not mention http or https protocol)\n",
    "http_https_other_percentages = http_https_other_percentages.drop(columns=['other'])\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(3.5, 3))\n",
    "plt.plot(http_https_other_percentages.index, http_https_other_percentages['http'], marker='o', color='#492e6b', label='HTTP')\n",
    "plt.plot(http_https_other_percentages.index, http_https_other_percentages['https'], marker='o', color='#405f82', label='HTTPS')\n",
    "plt.xticks(fontsize=8)\n",
    "plt.yticks(fontsize=8)\n",
    "plt.xlabel('Year', fontsize=8)\n",
    "plt.ylabel('Percentage of Total URLs', fontsize=8)\n",
    "plt.xticks(http_https_other_percentages.index, rotation=45)\n",
    "plt.legend(title='URL Type')\n",
    "plt.savefig('graphs/http_vs_https.pgf')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ac50854009c198",
   "metadata": {},
   "source": [
    "# Repository URL and Id Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "832199287f1e4bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average percentage of collisions: 14.76%\n",
      "Correlation: 0.6405\n",
      "p-value: 0.087\n"
     ]
    }
   ],
   "source": [
    "# Grouping by year and id_repo, counting unique URLs per id_repo\n",
    "poms_repos_df = all_poms_repos\n",
    "poms_repos_df['url_repo'] = poms_repos_df['url_repo'].str.rstrip('/')\n",
    "poms_repos_df['releaseYear'] = pd.to_datetime(poms_repos_df['releaseDate']).dt.year\n",
    "unique_urls_per_id_year = poms_repos_df.groupby(['releaseYear', 'id_repo'])['url_repo'].nunique()\n",
    "\n",
    "# Finding the ids with at least two different urls (collisions)\n",
    "collision_ids_per_year = unique_urls_per_id_year[unique_urls_per_id_year > 1]\n",
    "\n",
    "# Counting total ids and collision ids per year\n",
    "total_ids_per_year = poms_repos_df.groupby('releaseYear')['id_repo'].nunique()\n",
    "collision_count_per_year = collision_ids_per_year.groupby(level=0).count()\n",
    "\n",
    "# Calculating the percentage of ids with collisions per year\n",
    "collision_percentage_per_year = (collision_count_per_year / total_ids_per_year) * 100\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(3.5, 3))\n",
    "plt.subplots_adjust(bottom=0.2)\n",
    "bars = sns.barplot(x=collision_percentage_per_year.index, y=collision_percentage_per_year.values, palette='viridis')\n",
    "\n",
    "for bar in bars.patches:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, yval + 0.5, f'{yval:.2f}%', ha='center', va='bottom', fontsize=6)\n",
    "plt.ylim(0, 1.2 * max(collision_percentage_per_year.values))\n",
    "plt.xticks(rotation=45, horizontalalignment='right')\n",
    "plt.xticks(fontsize=8)\n",
    "plt.yticks(fontsize=8)\n",
    "plt.xlabel('Year', fontsize=8)\n",
    "plt.ylabel('Percentage of Collisions', fontsize=8)\n",
    "plt.savefig('graphs/id_collisions.pgf')\n",
    "plt.close()\n",
    "\n",
    "print(f'Average percentage of collisions: {collision_percentage_per_year.mean():.2f}%')\n",
    "\n",
    "correlation, p_value = pearsonr(collision_percentage_per_year.index, collision_percentage_per_year.values)\n",
    "print(f'Correlation: {correlation:.4f}' + '\\n' + f'p-value: {p_value:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d39196a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
